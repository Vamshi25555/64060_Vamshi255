---
title: "FML Assignment 2"
output:
  pdf_document: default
  html_document: default
date: "2023-10-16"
---

```{r}
# Loading the required libraries

library(class)
library(caret)
library(e1071)
library(dplyr)
```

```{r}

#Loading the data set
Accidents.data <- read.csv("C:/Users/navat/Downloads/accidentsFull.csv")
```
1) Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?

```{r}

Accidents.data$INJURY=ifelse(Accidents.data$MAX_SEV_IR%in% c(1,2),"yes","no")
table(Accidents.data$INJURY)

t(t(names(Accidents.data)))
```

2) Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 24 records. Use all three variables in the pivot table as rows/columns.

```{r}
# Pivot table for the data

Acc.data <- Accidents.data[1:24,c("INJURY","WEATHER_R","TRAF_CON_R")]

Acc.data

Piv.table <- ftable(Acc.data)

Piv.table2 <- ftable(Acc.data[,-1])


```

2.1) Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.

```{r}

#If the injury = Yes

Combination1 <- Piv.table[3,1]/Piv.table2[1,1]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=0):",Combination1,"\n")

Combination2 <- Piv.table[3,2]/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=1):",Combination2,"\n")

Combination3 <- Piv.table[3,3]/Piv.table2[1,3]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=2):",Combination3,"\n")

Combination4 <- Piv.table[4,1]/Piv.table2[2,1]
cat("P(INJURY=Yes|WEATHER_R=2 and TRAF_CON_R=0):",Combination4,"\n")

Combination5 <- Piv.table[4,2]/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=2 and TRAF_CON_R=1):",Combination5,"\n")

Combination6 <- Piv.table[4,3]/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=2 and TRAF_CON_R=2):",Combination6,"\n")

# If the injury = No

SCombination1 <- Piv.table[1,1]/Piv.table2[1,1]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=0):",SCombination1,"\n")

SCombination2 <- Piv.table[1,2]/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=1):",SCombination2,"\n")

SCombination3 <- Piv.table[1,3]/Piv.table2[1,3]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=2):",SCombination3,"\n")

SCombination4 <- Piv.table[2,1]/Piv.table2[2,1]
cat("P(INJURY=Yes|WEATHER_R=2 and TRAF_CON_R=0):",SCombination4,"\n")

SCombination5 <- Piv.table[2,2]/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=2 and TRAF_CON_R=1):",SCombination5,"\n")

SCombination6 <- Piv.table[2,3]/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=2 and TRAF_CON_R=2):",SCombination6,"\n") 

#We can see the probabilities now

```

2.2) Classify the 24 accidents using these probabilities and a cutoff of 0.5.

```{r}

#for the cutoff = 0.5 for 24 records

Probability.of.injury <- rep(0,24)
for(i in 1:24){print(c(Acc.data$WEATHER_R[i],Acc.data$TRAF_CON_R[i]))}

if(Acc.data$WEATHER_R[i]=="1"&&Acc.data$TRAF_CON_R[i]=="0"){Probability.of.injury[i]=Combination1
} else if(Acc.data$WEATHER_R[i]=="1"&&Acc.data$TRAF_CON_R[i]=="1"){Probability.of.injury[i]=Combination2
} else if(Acc.data$WEATHER_R[i]=="1"&&Acc.data$TRAF_CON_R[i]=="2"){Probability.of.injury[i]=Combination3 
} else if(Acc.data$WEATHER_R[i]=="2"&&Acc.data$TRAF_CON_R[i]=="0"){Probability.of.injury[i]=Combination4
} else if(Acc.data$WEATHER_R[i]=="2"&&Acc.data$TRAF_CON_R[i]=="1"){Probability.of.injury[i]=Combination5
} else if(Acc.data$WEATHER_R[i]=="2"&&Acc.data$TRAF_CON_R[i]=="2"){Probability.of.injury[i]=Combination6}
```

```{r}

Acc.data$probability.of.injury = Probability.of.injury
Acc.data$probability.of.prediction = ifelse(Acc.data$probability.of.injury>0.5, "yes","no")

head(Acc.data)

```


2.3) Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.

```{r}

Injury.yes=Piv.table[3,2]/Piv.table2[1,2]
I=(Injury.yes*Piv.table[3,2])/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=1):", Injury.yes,"\n")

Injury.No=Piv.table[1,2]/Piv.table2[1,2]
I=(Injury.No*Piv.table[3,2])/Piv.table2[1,2]
cat("P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=1):", Injury.No,"\n")

```
2.4) Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?

```{r}

Bayes_data <- naiveBayes(INJURY~TRAF_CON_R+WEATHER_R,data = Acc.data)

n.Acc.data <- predict(Bayes_data,newdata = Acc.data,type = "raw")
Acc.data$Naive.bayes.prediction.of.probabilities <- n.Acc.data[,2]

Bayes_data1 <- train(INJURY~TRAF_CON_R+WEATHER_R,data = Acc.data,method="nb")

predict(Bayes_data1,newdata=Acc.data[,c("INJURY","WEATHER_R","TRAF_CON_R")])
predict(Bayes_data1,newdata=Acc.data[,c("INJURY","WEATHER_R","TRAF_CON_R")],type = "raw")
```

3. Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%).

```{r}
accidents=Acc.data[c(-24)]

set.seed(1)
accidents.index=sample(row.names(accidents),0.6*nrow(accidents)[1])
validation.index=setdiff(row.names(accidents),accidents.index)

accidents.dataframe=accidents[accidents.index,]
validation.dataframe=accidents[validation.index,]

dim(accidents.dataframe)
dim(validation.dataframe)

normalised.values <- preProcess(accidents.dataframe[,],method=c("center","scale"))
accidents.normalised <- predict(normalised.values,accidents.dataframe[, ])
validation.normalised.dataframe <- predict(normalised.values,validation.dataframe[, ])

levels(accidents.normalised)
class(accidents.normalised$INJURY)
accidents.normalised$INJURY <- as.factor(accidents.normalised$INJURY)

```

3.1 Run a naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.

```{r}

Naive.bayes.model <- naiveBayes(INJURY~WEATHER_R+TRAF_CON_R, data = accidents.normalised)

Predictions.of.nb <- predict(Naive.bayes.model,newdata=validation.normalised.dataframe)

#Factors in validation dataset should match with training dataset.

validation.normalised.dataframe$INJURY <- factor(validation.normalised.dataframe$INJURY,levels = levels(accidents.normalised$INJURY))

#confusion matrix

confusionMatrix(Predictions.of.nb,validation.normalised.dataframe$INJURY)

#Overall error rate calculation

Overall.error <- 1 - sum(Predictions.of.nb==validation.normalised.dataframe$INJURY)/nrow(validation.normalised.dataframe)

Overall.error

```
#Summary of the above output

It is considered that there may be injuries when an accident has just been reported and no additional information is provided (INJURY = Yes). In order to appropriately portray the accident's highest amount of harm, MAX_SEV_IR, this assumption is made. According to the instructions, if MAX_SEV_IR is 1 or 2, there has been some sort of injury (INJURY = Yes). If MAX_SEV_IR, on the other hand, equals 0, it means that there is no injury (INJURY = No).

As per the above data, there are 20721 cases with no injury and 21462 cases with injuries.

We now obtain a different dataframe with only variables as injury, weather and traffic. 

Created a pivot table only with above variables. Also, calculated the bayes probabilities with all the combinations.

Using the cutoff of 0.5 for all the 24 records of accidents in the above variables with the given attributes of weather and traffic, computed the naive bayes conditional probability of injuries.

The manual predictions of the naive bayes are:

P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=1): 0 
P(INJURY=Yes|WEATHER_R=1 and TRAF_CON_R=1): 1 

The predictions to the exact bayes models and naive bayes models are as follows:

[1] yes no  no  yes yes no  no  yes no  no  no  yes yes yes
[15] yes yes no  no  no  no  yes yes no  no 
Levels: no yes

[1] yes no  no  yes yes no  no  yes no  no  no  yes yes yes
[15] yes yes no  no  no  no  yes yes no  no 
Levels: no yes

We can observe that both the exact bayes and naive bayes have the same results and orders of ranking is consistent between both. 

Further, we also split the data to training (60%) and validation (40%), to let the model perdict the future unseen accidents with the model.

These sets have different functions whereas training set is used to train the model with the data inputs based on the past accidents and validation set is used to validate the training set as reference to label the accidents in future cases. 

After splitting the data, we have to normalise to avoid errors, normalising is nothing but building consistence within the data types such as numeric varibles or integers.

Here are the statistics of the model as per the output:

Accuracy : 0.3             
                 95% CI : (0.0667, 0.6525)
    No Information Rate : 0.5             
    P-Value [Acc > NIR] : 0.9453          
                                          
                  Kappa : -0.4            
                                          
 Mcnemar's Test P-Value : 0.4497          
                                          
            Sensitivity : 0.600           
            Specificity : 0.000           
         Pos Pred Value : 0.375           
         Neg Pred Value : 0.000           
             Prevalence : 0.500           
         Detection Rate : 0.300           
   Detection Prevalence : 0.800           
      Balanced Accuracy : 0.300           
                                          
       'Positive' Class : no              
                                          
Accuracy : 0.3 which says that the 30% of the predictions are correct.

Sensitivity is 0.3 which is true positive rate. 

specificity says that how much percent of the time can the model can identify the negative cases which is 0 in this solution.

As per the summary, we can say that the model is not performing well.


























































